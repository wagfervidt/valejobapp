const moo = require('moo');

const syntaxKeywords = [
  'break',
  'case',
  'catch',
  'const',
  'continue',
  'debugger',
  'default',
  'delete',
  'do',
  'else',
  'finally',
  'for',
  'function',
  'if',
  'in',
  'instanceof',
  'let',
  'new',
  'return',
  'switch',
  'this',
  'throw',
  'try',
  'typeof',
  'var',
  'void',
  'while',
  'with',
];

const valueKeywords = [
  'true',
  'false',
  'null',
  'undefined',
  'NaN',
];

const keywords = syntaxKeywords.concat(valueKeywords);
const keywordMapping = {};
keywords.forEach((keyword) => {
  keywordMapping[keyword] = true;
});
const functionNameRegex = /^[A-Z][A-Z0-9_]*$/;

const lexer = moo.compile({
  whitespace: / +/,
  identifier: {
    match: /[a-zA-Z_$][a-zA-Z0-9_$]*/,
    type: (identifier) => {
      if (keywordMapping[identifier]) {
        return 'keyword';
      }
      if (functionNameRegex.test(identifier)) {
        return 'functionName';
      }
      return 'identifier';
    },
  },
  number: {
    match: /[0-9]+(?:\.[0-9]+)?(?:e-?[0-9]+)?/,
    value: x => parseFloat(x),
  },
  // Either single-quoted or double-quoted string
  string: {
    match: /"(?:[^\\"]|\\[/bfnrt\\"']|\\u[0-9A-Fa-f]{4})*"|'(?:[^\\']|\\[/bfnrt\\"']|\\u[0-9A-Fa-f]{4})*'/,
    // For single-quoted string need to convert before parsing as JSON
    value: x => JSON.parse(
      x[0] === "'" ? `"${x.slice(1, -1).replace(/[\\]?"/g, '\\"').replace(/\\'/g, "'")}"` : x,
    ),
  },
  newline: { match: /\n/, lineBreaks: true },
  operator: /[?:%*/+-]|\|\||&&|!(?!=)|[!=]==?|[<>]=?/,
  leftParenthesis: /\(/,
  rightParenthesis: /\)/,
  leftBracket: /\[/,
  rightBracket: /\]/,
  leftBrace: /\{/,
  rightBrace: /\}/,
  comma: /,/,
  accessor: /\./,
  error: moo.error,
});

const readableTokenTypes = ['newline', 'whitespace', 'string', 'boolean'];

function describeToken(token) {
  const { type, text } = token;
  if (type === 'error') {
    return JSON.stringify(text[0]);
  }
  if (type === 'keyword' && syntaxKeywords.indexOf(text) >= 0) {
    return `reserved keyword ${JSON.stringify(text)}`;
  }
  if (readableTokenTypes.indexOf(type) >= 0) {
    return type;
  }
  return JSON.stringify(text);
}

function parseTokens(formula) {
  lexer.reset(formula);
  const tokens = [];
  let token;
  // eslint-disable-next-line no-cond-assign
  while (token = lexer.next()) {
    tokens.push({
      text: token.text,
      offset: token.offset,
      length: token.text.length,
      type: token.type,
    });
  }
  return tokens;
}

module.exports.describeToken = describeToken;
module.exports.keywords = keywords;
module.exports.lexer = lexer;
module.exports.parseTokens = parseTokens;
module.exports.syntaxKeywords = syntaxKeywords;
module.exports.valueKeywords = valueKeywords;
